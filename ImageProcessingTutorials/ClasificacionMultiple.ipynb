{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGjTNwLR+kBzlMhlgfM/AT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathalyDM/-Bioinformatics_course/blob/main/ImageProcessingTutorials/ClasificacionMultiple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Importar las bibliotecas necesarias**\n",
        "Importa las bibliotecas y módulos necesarios para ejecutar el código.\n",
        "os y numpy son bibliotecas estándar de Python para operaciones del sistema y operaciones matemáticas, respectivamente.\n",
        "tensorflow es la biblioteca principal para construir y entrenar modelos de aprendizaje profundo.\n",
        "ImageDataGenerator es una clase de Keras para la aumentación de datos.\n",
        "ResNet50, InceptionV3, Xception, VGG16, y VGG19 son arquitecturas de modelos preentrenados disponibles en Keras.\n",
        "albumentations es una biblioteca de aumentación de imágenes rápida y flexible."
      ],
      "metadata": {
        "id": "XQbrnBDWlzU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqawzqXglh61"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, InceptionV3, Xception, VGG16, VGG19\n",
        "from tensorflow.keras import layers, models\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, model_name):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9SdaXu2mpmQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images, augmented_images):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(4):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, 4, i + 5)\n",
        "        plt.imshow(augmented_images[i])\n",
        "        plt.title('Augmented')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "tFZKngVurkxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Configurar los directorios**\n",
        "- Define las rutas a los directorios de entrenamiento y validación.\n",
        "- `train_dir` y `val_dir` deben contener subcarpetas para cada clase.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOw0NQ3wmOTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'path_to_your_dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "\"\"\"\n",
        "dataset\n",
        "│\n",
        "└───train\n",
        "│   └───control\n",
        "│   │   └───image1.jpg\n",
        "│   │   └───image2.jpg\n",
        "│   │   ...\n",
        "│   └───covid\n",
        "│   │   └───image1.jpg\n",
        "│   │   └───image2.jpg\n",
        "│   │   ...\n",
        "│   └───pneumonia-viral\n",
        "│       └───image1.jpg\n",
        "│       └───image2.jpg\n",
        "│       ...\n",
        "│\n",
        "└───val\n",
        "    └───control\n",
        "    │   └───image1.jpg\n",
        "    │   └───image2.jpg\n",
        "    │   ...\n",
        "    └───covid\n",
        "    │   └───image1.jpg\n",
        "    │   └───image2.jpg\n",
        "    │   ...\n",
        "    └───pneumonia-viral\n",
        "        └───image1.jpg\n",
        "        └───image2.jpg\n",
        "        ...\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "s-iEpzXNmY3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Preprocesamiento y Aumentación de Datos con Albumentations**\n",
        "Define las rutas a los directorios de entrenamiento y validación.\n",
        "`train_dir` y `val_dir` deben contener subcarpetas para cada clase.\n",
        "\n",
        "- Define una función para transformar las imágenes usando la biblioteca Albumentations.\n",
        "- Realiza volteo horizontal, ajuste de brillo y contraste, y normalización de las imágenes."
      ],
      "metadata": {
        "id": "RJ5QYgp1moX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def albumentations_transform(image):\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "    ])\n",
        "    image = transform(image=image)['image']\n",
        "    return image"
      ],
      "metadata": {
        "id": "5UynnO8Zmzbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Obtener y visualizar 4 imágenes aleatorias y sus versiones aumentadas**"
      ],
      "metadata": {
        "id": "QsSI83coru0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener un lote de imágenes del generador de entrenamiento\n",
        "images, _ = next(train_generator)\n",
        "\n",
        "# Aplicar la función de transformación de Albumentations a cada imagen\n",
        "augmented_images = [albumentations_transform(image) for image in images]\n",
        "\n",
        "# Visualizar las imágenes originales y aumentadas\n",
        "plot_images(images, augmented_images)"
      ],
      "metadata": {
        "id": "CjBlc232rtkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Generador de Datos**\n",
        "\n",
        "- Define una función para crear un generador de datos que leerá las imágenes de un directorio y aplicará las transformaciones definidas anteriormente.\n",
        "- El generador de datos es útil para leer y procesar imágenes en lotes durante el entrenamiento y la evaluación del modelo."
      ],
      "metadata": {
        "id": "6GwYg_edm7i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(directory, batch_size):\n",
        "    datagen = ImageDataGenerator(preprocessing_function=albumentations_transform)\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        class_mode='categorical',\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return generator"
      ],
      "metadata": {
        "id": "NWkZ9FbNm0TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Crear Generadores de Datos**\n",
        "\n",
        "Crea generadores de datos para los conjuntos de entrenamiento y validación usando la función definida anteriormente."
      ],
      "metadata": {
        "id": "3UqiDbaRnKqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = data_generator(train_dir, batch_size=32)\n",
        "val_generator = data_generator(val_dir, batch_size=32)"
      ],
      "metadata": {
        "id": "ocO7UwecnSs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Construir, Compilar, Entrenar y Evaluar los Modelos**"
      ],
      "metadata": {
        "id": "qpJG2RUAm0BF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1 ResNet50**"
      ],
      "metadata": {
        "id": "O4EufiTUn2Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "plot_history(history, 'ResNet50')\n",
        "model.save('ResNet50_model.h5')\n",
        "print(f'ResNet50 - Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "tI6bZXXJnTc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2 InceptionV3**"
      ],
      "metadata": {
        "id": "dMaX7purorpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "plot_history(history, 'InceptionV3')\n",
        "model.save('InceptionV3_model.h5')\n",
        "print(f'InceptionV3 - Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "dSRELXszoxKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3 Xception**"
      ],
      "metadata": {
        "id": "GofNKDudo3wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = Xception(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "plot_history(history, 'Xception')\n",
        "model.save('Xception_model.h5')\n",
        "print(f'Xception - Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "HFSg4MdXo7ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.4 VGG16**"
      ],
      "metadata": {
        "id": "INKt6OiKo-La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "plot_history(history, 'VGG16')\n",
        "model.save('VGG16_model.h5')\n",
        "print(f'VGG16 - Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "4Pw4r1LGpC2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.5 VGG19**"
      ],
      "metadata": {
        "id": "M_tMh_bKpHao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG19(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "plot_history(history, 'VGG19')\n",
        "model.save('VGG19_model.h5')\n",
        "print(f'VGG19 - Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "w7kOhvMepRLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Sección de Inferencia**\n",
        "\n",
        "- `load_random_images`: Esta función carga rutas de imágenes aleatorias del directorio de datos proporcionado.\n",
        "-`preprocess_and_load_image`: Esta función carga, preprocesa y transforma una imagen al formato correcto para la inferencia del modelo.\n",
        "-Luego, para cada modelo entrenado, cargamos el modelo, preprocesamos las imágenes aleatorias cargadas y realizamos inferencias.\n",
        "-Imprimimos las clases predichas junto con la confianza para cada imagen usando cada modelo."
      ],
      "metadata": {
        "id": "M7o-c6zl3xZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_random_images(directory, num_images):\n",
        "    all_images = []\n",
        "    for subdir in os.listdir(directory):\n",
        "        subdir_path = os.path.join(directory, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            all_images.extend([os.path.join(subdir_path, file) for file in os.listdir(subdir_path)])\n",
        "    selected_images = random.sample(all_images, num_images)\n",
        "    return selected_images\n",
        "\n",
        "def preprocess_and_load_image(img_path):\n",
        "    img = k_image.load_img(img_path, target_size=(224, 224))  # adjust target_size according to your model input size\n",
        "    img_array = k_image.img_to_array(img)\n",
        "    img_array = albumentations_transform(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to represent a batch of size 1\n",
        "    return img_array\n",
        "\n",
        "# Load a few random images\n",
        "num_images = 5\n",
        "random_images = load_random_images(train_dir, num_images)\n",
        "\n",
        "# Load the trained models and perform inference\n",
        "model_names = ['ResNet50', 'InceptionV3', 'Xception', 'VGG16', 'VGG19']\n",
        "for model_name in model_names:\n",
        "    print(f'Performing inference using {model_name} model...')\n",
        "    model = load_model(f'{model_name}_model.h5')  # Load the trained model\n",
        "    for img_path in random_images:\n",
        "        img_array = preprocess_and_load_image(img_path)\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions, axis=1)\n",
        "        print(f'Image {img_path} is predicted as class {predicted_class[0]} with confidence {predictions[0][predicted_class[0]]:.2f}')\n",
        "    print('\\n' + '='*80 + '\\n')  # Print separator between different models' predictions"
      ],
      "metadata": {
        "id": "7G54yEal38ZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}